{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a2c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved preprocessed CSVs\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('data/processed/preprocessed_train.csv')\n",
    "df_test  = pd.read_csv('data/processed/preprocessed_test.csv')\n",
    "\n",
    "# Recreate X / y variables used by models\n",
    "X_train = df_train['clean_reviewText']   # or 'reviewText' if you prefer raw\n",
    "y_train = df_train['sentiment']\n",
    "\n",
    "X_test  = df_test['clean_reviewText']\n",
    "y_test  = df_test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "304dc858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Model Competition ---\n",
      "\n",
      "Training Naive Bayes...\n",
      "Training completed in 0.26 seconds.\n",
      "Naive Bayes Accuracy: 0.9631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00        43\n",
      "    Positive       0.96      1.00      0.98      1121\n",
      "\n",
      "    accuracy                           0.96      1164\n",
      "   macro avg       0.48      0.50      0.49      1164\n",
      "weighted avg       0.93      0.96      0.94      1164\n",
      "\n",
      "\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 0.37 seconds.\n",
      "Logistic Regression Accuracy: 0.9570\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.44      0.60      0.51        43\n",
      "    Positive       0.98      0.97      0.98      1121\n",
      "\n",
      "    accuracy                           0.96      1164\n",
      "   macro avg       0.71      0.79      0.74      1164\n",
      "weighted avg       0.96      0.96      0.96      1164\n",
      "\n",
      "\n",
      "--- Competition Finished ---\n",
      "Winner: Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:209: RuntimeWarning: divide by zero encountered in matmul\n",
      "  norm2_w = weights @ weights if weights.ndim == 1 else squared_norm(weights)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:209: RuntimeWarning: overflow encountered in matmul\n",
      "  norm2_w = weights @ weights if weights.ndim == 1 else squared_norm(weights)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/sklearn/linear_model/_linear_loss.py:209: RuntimeWarning: invalid value encountered in matmul\n",
      "  norm2_w = weights @ weights if weights.ndim == 1 else squared_norm(weights)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Try to import a local preprocessing module (if present) using a dynamic import.\n",
    "# Using importlib.util.find_spec avoids a static \"Import could not be resolved\" lint error.\n",
    "import importlib\n",
    "import importlib.util\n",
    "\n",
    "preprocessing_pipeline = None\n",
    "spec = importlib.util.find_spec('pre_processing')\n",
    "if spec is not None:\n",
    "    try:\n",
    "        module = importlib.import_module('pre_processing')\n",
    "        preprocessing_pipeline = getattr(module, 'preprocessing_pipeline', None)\n",
    "    except Exception:\n",
    "        preprocessing_pipeline = None\n",
    "\n",
    "# Fall back to inline minimal TF-IDF if pre_processing not available\n",
    "if preprocessing_pipeline is None:\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    preprocessing_pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1, 2)))\n",
    "    ])\n",
    "\n",
    "# X_train, X_test, y_train, y_test\n",
    "# preprocessing_pipeline (The TextCleaner + TfidfVectorizer)\n",
    "\n",
    "# 1. Define the Candidate Models\n",
    "# We extend the preprocessing pipeline by adding a classifier step\n",
    "models = {\n",
    "    \"Naive Bayes\": Pipeline([\n",
    "        ('preprocessor', preprocessing_pipeline),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ]),\n",
    "\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('preprocessor', preprocessing_pipeline),\n",
    "        ('classifier', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 2. The Training Loop\n",
    "results = {}\n",
    "\n",
    "print(\"--- Starting Model Competition ---\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train (Fit)\n",
    "    # The pipeline runs Cleaner -> TF-IDF -> Model automatically\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"Training completed in {train_time:.2f} seconds.\")\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    # We print the report to see Precision/Recall for the Minority Class (0)\n",
    "    print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))\n",
    "\n",
    "print(\"\\n--- Competition Finished ---\")\n",
    "print(\"Winner:\", max(results, key=results.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b88aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'sentiment_model.pkl'\n",
      "Review: The product arrived broken and the support was rude.\n",
      "Sentiment: Negative\n",
      "Confidence: 0.79\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 1. Select best model\n",
    "final_model = models[\"Logistic Regression\"]\n",
    "\n",
    "# 2. Save to disk\n",
    "# This creates a binary file containing the logic, vocabulary, and weights\n",
    "joblib.dump(final_model, 'sentiment_model.pkl')\n",
    "\n",
    "print(\"Model saved as 'sentiment_model.pkl'\")\n",
    "\n",
    "# 3. Verification\n",
    "# Let's try to load it back and predict on a fake review to be sure\n",
    "loaded_model = joblib.load('sentiment_model.pkl')\n",
    "test_review = [\"The product arrived broken and the support was rude.\"]\n",
    "prediction = loaded_model.predict(test_review)\n",
    "probability = loaded_model.predict_proba(test_review)\n",
    "\n",
    "print(f\"Review: {test_review[0]}\")\n",
    "print(f\"Sentiment: {'Positive' if prediction[0] == 1 else 'Negative'}\")\n",
    "print(f\"Confidence: {max(probability[0]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561716ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
